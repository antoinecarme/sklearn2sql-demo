
One can consider this small report as the sklearn2sql feeedback on the database ecosystem behavior when it comes to machine-generated SQL code for machine learning objects deployment. If you are a database vendor/developer and are interested in improving your database for in-databaase modeling, this can be a starting point.

Please note that here , we use a database to predict machine learning models outputs, like a specialized CPU. the same way a deep learning model can be trained or predicted with a GPU or a FPGA.

## Common Table Expressions (CTEs)

A must. All the SQL code generated by sklearn2sl is baed on CTEs. CTEs are kind of very handy table expressions and are seen as tables. CTE usage is a recommended way of generating useful SQL. SQL written this way is clear and can be debugged easily. The structure of th SQL code matches the underlying machine learning model. Using CTEs also helps the SQL optimizer. Databases that do not completely support CTEs are not worth working on ;)

## Floating Point Types / Computations

sklearn2sql uses float64 doubles for all its computations (scores, class probabilties, etc). It would be nice if all databases shared the same IEEE-754 standard for DOUBLE PRECISION types (one can dream a little bit;). This is not the case and a lot of overflow/underflow and precision issues are observed when executing the SQL code for such or such database. Teradata has 13 decimal points supported. | exp, log, softmax, naive-bayes etc

## NaN/Infinity behavior
Oracle does a very strange job here !!!! Other databases, not always better. We use MAX_DOUBLE to represent +Infitnity ...

## Wide tables

Not all databases have the same behavior when it comes to the maximum number of columns in a table or a CTE. Around 1000 is a common value. | one hot encoding can generate a separate column for each different value in the training dataset columns. Not very useful limitations nowadays. Database vendors : Please get rid of this or add it as an option (user-controllable).

## SQL statement complexity

A lot of databases do not allow using more than N (64 for sqlite ??) tables/froms/selectables/CTEs in the same select statement.
Database vendors : SQL Complexity errors are not always justified. If you really want to set a limitation, add it as an option.

## SQL expression complexity

Very complex epressions (using more than a number of columns in the same expression) are not always allowed. MS SQL server does not allow very complex case when expressions (depth limited to 10). expression depth in sqlite.
Database vendors : SQL Complexity errors are not always justified as not all databases have this issue. Some R&D may be helpful. Also erro messages can be raised only when the system resources are missing (CPU/disk/memory), a depth limit of 10 is exaggerated when one has gigagbytes of memory. If you really want to set the max depth to 10, add it as an option.

## math functions

Not all databases have tanh etc, density functions etc

https://en.wikibooks.org/wiki/SQL_Dialects_Reference/Functions_and_expressions/Math_functions/Trigonometric_functions

https://stackoverflow.com/questions/38939718/how-to-calculate-tanh-in-sql-server-2012

## Temporary Tables

sklearn2sql sometimes generates temporary tables to precompute very complex expressions (as a workaround for complexity issues).
Their behavior is not always consistant between databases (global or not, session-based, storage : memory-based  etc)

## recurisve CTEs

Not always supported. Used in recurrent neural networks | LSTM, GRU, RNN

https://github.com/antoinecarme/keras2sql/issues/2

## Table/column Names Limits

sklearn2sql internally generates partially random temporary tables names and tries to avoid 
When sklearn2sql development started, Oracle did not support table names with more than 30 chars. Seems to be correcetd in oracle 18. GOOD.

## Identifier name case sensitivity

Upper case of lower case forced by the database can be a source of lookup errors.
Database vendors : Naming objects is a user freedom. Please get rid of this too 1900's feature !!!!


